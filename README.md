# Neural Network Advanced Techniques Library

This library provides two advanced techniques for neural network implementation and optimization:

1. **Splitting Neural Networks (`split_nn.py`):** This allows for a neural network model to be split into two separate models at a specified layer.
2. **Knowledge Distillation (`knowledge_distillation_nn.py`):** Knowledge distillation trains a smaller student model using the knowledge of a larger teacher model, typically resulting in the student model achieving higher performance than if trained directly.
